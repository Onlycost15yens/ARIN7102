{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. QA retrivel with HealthCareMagic-100k-QA\n",
    "100k real conversations between patients and doctors from HealthCareMagic.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def load_json(filename):\n",
    "    \"\"\"Load JSON file containing medical QA data.\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def save_json(data, filename):\n",
    "    \"\"\"Save JSON data to file.\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "def encode_text(text, model, tokenizer):\n",
    "    \"\"\"Encode text into BERT embeddings.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Convert to list for JSON serialization\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()[0].tolist()\n",
    "\n",
    "def preprocess_dataset_with_embeddings(json_file, model, tokenizer, batch_size=100):\n",
    "    \"\"\"\n",
    "    Process the dataset in batches, adding embeddings to each entry\n",
    "    and saving after each batch to avoid memory issues.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = load_json(json_file)\n",
    "    \n",
    "    # Create a backup of original file\n",
    "    backup_file = json_file + '.backup'\n",
    "    if not os.path.exists(backup_file):\n",
    "        save_json(data, backup_file)\n",
    "        print(f\"Original data backed up to {backup_file}\")\n",
    "    \n",
    "    # Track which entries already have embeddings\n",
    "    for i in tqdm(range(0, len(data), batch_size), desc=\"Processing batches\"):\n",
    "        batch = data[i:min(i+batch_size, len(data))]\n",
    "        modified = False\n",
    "        \n",
    "        for j, entry in enumerate(batch):\n",
    "            # Skip if already has embedding\n",
    "            if \"embedding\" not in entry:\n",
    "                # Generate combined text\n",
    "                text = entry[\"input\"] + \" \" + entry[\"output\"]\n",
    "                # Encode and store\n",
    "                entry[\"embedding\"] = encode_text(text, model, tokenizer)\n",
    "                modified = True\n",
    "                \n",
    "        \n",
    "        if modified:\n",
    "            # Save after each batch\n",
    "            save_json(data, json_file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def find_best_matches_from_preprocessed(json_file, query, model, tokenizer, k=3):\n",
    "    \"\"\"Find best matches using preprocessed embeddings in the JSON file.\"\"\"\n",
    "    # Load preprocessed data with embeddings\n",
    "    data = load_json(json_file)\n",
    "    \n",
    "    # Encode query\n",
    "    query_embedding = np.array(encode_text(query, model, tokenizer))\n",
    "    \n",
    "    # Calculate similarities without loading all embeddings at once\n",
    "    similarities = []\n",
    "    for i, entry in enumerate(tqdm(data, desc=\"Calculating similarities\")):\n",
    "        if \"embedding\" in entry:\n",
    "            entry_embedding = np.array(entry[\"embedding\"])\n",
    "            # Calculate cosine similarity\n",
    "            sim = cosine_similarity([query_embedding], [entry_embedding])[0][0]\n",
    "            similarities.append((i, sim))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-k results\n",
    "    results = []\n",
    "    for i in range(min(k, len(similarities))):\n",
    "        idx, score = similarities[i]\n",
    "        results.append((data[idx][\"input\"], data[idx][\"output\"], score))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"Dataset/HealthCareMagic-100k-QA.json\"\n",
    "# Initialize BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# First time: preprocess and add embeddings to JSON file\n",
    "preprocess_dataset_with_embeddings(json_file, model, tokenizer, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3be844807a40fc8b737cd116e8d4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating similarities:   0%|          | 0/112165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 | Score: 0.8589\n",
      "Query: I have been diagnosed with hypertension and have gone through four diff. B/P meds. but I have a hypersensitivity to some meds. and have been having intolerable side effects with all B/P meds. I have taken so far  with palpitations being the most bothersome. What should I do ? I am 22yrs old I am 5/5 & 1/2 and  currently weigh 231lbs  I have a history of headahes, chrons disease, irregular heartbeat, fibromyalgia glaucoma,  fatty liver disease asthma and sinusitis...\n",
      "Answer: I understand that it is very difficult when you have multiple Chat Doctor.  Losing weight, healthy diet and regular exercise will definitely help your blood pressure. Cutting out all salt, processed food, alcohol and caffeine can lower blood pressure and help with weight loss. The Mediterranean diet is best with a focus on fruits, vegetables, whole grains and lean protein. Exercise can simply be walking. And it will lower blood pressure. Start slowly and build up to 30-60 minutes per day. Good luck\n",
      "\n",
      "Rank 2 | Score: 0.8470\n",
      "Query: I have had right flank pain for at least three weeks. It keeps me awake at night. Aleve settles the pain for a couple of hours. I find it hard to reposition myself in bed. I have no fever, and no swelling in the extremities. Urination is regular, urine is straw colored.\n",
      "Answer: Hi, Welcome to Chat Doctor forum.  The reason for the pain in the right flanks might be due to the gastric irritation, kidney infection, stone in the kidney, ureter, hepatitis, gallbladder infection, or stones, colitis, appendicitis.  I advise you to consult a surgeon for diagnosis and treatment. You may need to have gastrostomy, ultrasound, for confirmation.  Take more of green leafy vegetables, pulses, sprouts, and protein rich foods to hasten the recovery.  Wishing for a quick and complete recovery. Thank you.\n",
      "\n",
      "Rank 3 | Score: 0.8432\n",
      "Query: my husband had a cabinet fall on top of his head yesterday. he said it did not knock him out, but has been having bad headaches and when he turns his head a certain way it hurts. he said it never became a knot, it is a soft spot on the top of his head. should he go to the er?\n",
      "Answer: Hi, At this stage I suggest he does not need to go to the ED. Take paracetamol and ibuprofen for pain relief. The soft spot on the top of his head is the swelling caused by the impact. This will reduce over the next few days. If the headache persists for longer than 48 hours, I would advise going to the ED for assessment. Other signs to watch for would be problems with vision, vomiting, Chat Doctor.  I hope he feels better soon. \n",
      "\n",
      "Rank 4 | Score: 0.8424\n",
      "Query: I have Fibromyalgia and experience each day fine needles and pain througout my body. It comes and goes and I try to walk three times a day, and hope to go back to swimming at the local pool or go to Silver Sneakers. I don t take the pain killer pill Tramadol unless absolutely uncomfortable and can only take 1x a day. Is there anything more I should do everyday, also I take Calcium/Vitamin D tablet once a day and a multiple vitamin which often helps in a couple of hours. I think I should be on a regime each day but can t get regimented. I have lost 25 pounds but still need to lose another 50lbs. Thank you for any suggestions or regime I can do daily that may improve this pain, confused on clear treatments.\n",
      "Answer: Well, you certainly are taking the right actions to help fibromyalgia. Some of it is due to depression and antidepressants are generally used for it. Otherwise, it is perhaps a dysregulation of the nerves that damp down pain. This is more or less corrected by exercise up to the point of the exercise causing pain. The pain from the exercise resets pain perception. It is temporary and needs to be done regularly.\n",
      "\n",
      "Rank 5 | Score: 0.8422\n",
      "Query: I have severe pain in my higher back on the right side.  I have had it for three days and do not recall straining or twisting it.  lying flat seems to help, otherwise No position relieves the pain.  It takes my breath away like an ache that developes into a severe pain.  What could it be?\n",
      "Answer: Hi there. I would advise you to firstly get a X-ray of the back done and get it evaluated by an orthopedic. A pain which is relieved by rest could be bony in nature as well as due to muscle spasm. The first and foremost thing to do is rest. Try to curtail your activity as much as possible and take adequate rest. A good anti-inflammatory and muscle relaxant like Nicosia MR along with local heat therapy and analgesic gel massage. Tramadol can be taken if there isn't complete relief with the above. Final treatment depends on the X-ray diagnosis. I hope my advice has helped. Good luck\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"My head is spinning when I stand up, but not when sitting. I also feel nauseous.\"\n",
    "k = 5\n",
    "\n",
    "best_matches = find_best_matches_from_preprocessed(json_file, query, model, tokenizer, k)\n",
    "\n",
    "for i, (query, answer, score) in enumerate(best_matches):\n",
    "    print(f\"Rank {i+1} | Score: {score:.4f}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ClinicalBERT, LLM for medical scene\n",
    "This model was trained on a large multicenter dataset with a large corpus of 1.2B words of diverse diseases we constructed. We then utilized a large-scale corpus of EHRs from over 3 million patient records to fine tune the base language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MedPub, Disease - Symptom pair dataset\n",
    "Get the Disease - Symptom pairs from MedPub Dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 download dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Base URL for PubMed baseline files\n",
    "base_url = \"https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/\"\n",
    "\n",
    "# Define download directory\n",
    "download_dir = \"Dataset/pubmed_data\"\n",
    "\n",
    "# Create directory for downloaded files if it doesn't exist\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Download and extract files, in total 1274 files\n",
    "for i in tqdm(range(1, 10), desc=\"Processing files\"):\n",
    "    file_num = str(i).zfill(4)\n",
    "    gz_filename = f\"pubmed25n{file_num}.xml.gz\"\n",
    "    xml_filename = gz_filename[:-3]  # Remove .gz extension\n",
    "    xml_filepath = os.path.join(download_dir, xml_filename)\n",
    "    \n",
    "    # Skip if XML already exists\n",
    "    if os.path.exists(xml_filepath):\n",
    "        continue\n",
    "        \n",
    "    url = base_url + gz_filename\n",
    "    \n",
    "    try:\n",
    "        # Download gz file\n",
    "        gz_filepath = os.path.join(download_dir, gz_filename)\n",
    "        urllib.request.urlretrieve(url, gz_filepath)\n",
    "        \n",
    "        # Extract gz file\n",
    "        with gzip.open(gz_filepath, 'rb') as gz_file:\n",
    "            with open(xml_filepath, 'wb') as xml_file:\n",
    "                xml_file.write(gz_file.read())\n",
    "                \n",
    "        # Remove gz file after extraction\n",
    "        os.remove(gz_filepath)\n",
    "        \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error processing {gz_filename}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Extract the title and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the XML files\n",
    "xml_dir = \"Dataset/pubmed_data\"\n",
    "\n",
    "# List to store extracted data\n",
    "papers = []\n",
    "\n",
    "# Process each XML file\n",
    "for filename in tqdm(os.listdir(xml_dir), desc=\"Processing batches\"):\n",
    "    if not filename.endswith('.xml'):\n",
    "        continue\n",
    "    \n",
    "    filepath = os.path.join(xml_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(filepath)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extract data from each article\n",
    "        for article in root.findall('.//PubmedArticle'):\n",
    "            try:\n",
    "                # Extract PMID\n",
    "                pmid_elem = article.find('.//PMID')\n",
    "                pmid = pmid_elem.text if pmid_elem is not None else None\n",
    "                \n",
    "                # Extract abstract\n",
    "                abstract_elem = article.find('.//AbstractText')\n",
    "                abstract = abstract_elem.text if abstract_elem is not None else None\n",
    "                \n",
    "                # Only add if we have an abstract\n",
    "                if abstract:\n",
    "                    papers.append({\n",
    "                        'pmid': pmid,\n",
    "                        'abstract': abstract\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error extracting data from article: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error processing file {filename}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create DataFrame from the extracted data\n",
    "papers_df = pd.DataFrame(papers)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Total papers extracted: {len(papers_df)}\")\n",
    "papers_df.head()\n",
    "\n",
    "# Save to CSV\n",
    "papers_df.to_csv(\"Dataset/pubmed_papers.csv\", index=False)\n",
    "print(\"Data saved to Dataset/pubmed_papers.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generate the disease - symptom dataset\n",
    "Generate the disease - symptom dataset learning from the abstract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
